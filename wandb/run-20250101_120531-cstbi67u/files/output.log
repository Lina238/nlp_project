Epoch 1/1:   0%|                                                                               | 0/113 [00:39<?, ?it/s]
Traceback (most recent call last):
  File "C:\Users\Lina-pc\OneDrive\Bureau\nlp_devoir_q&a\retrain.py", line 90, in <module>
    retrain_model("saved_model", num_epochs=3, sample_size=1000)
  File "C:\Users\Lina-pc\OneDrive\Bureau\nlp_devoir_q&a\retrain.py", line 72, in retrain_model
    train_model(
  File "C:\Users\Lina-pc\OneDrive\Bureau\nlp_devoir_q&a\tp.py", line 296, in train_model
    loss.backward()
  File "C:\Python312\Lib\site-packages\torch\_tensor.py", line 581, in backward
    torch.autograd.backward(
  File "C:\Python312\Lib\site-packages\torch\autograd\__init__.py", line 347, in backward
    _engine_run_backward(
  File "C:\Python312\Lib\site-packages\torch\autograd\graph.py", line 825, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn
